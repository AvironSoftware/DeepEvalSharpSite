"use strict";(self.webpackChunkdocs_src=self.webpackChunkdocs_src||[]).push([[443],{5934:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"ContextualRecallMetric","title":"Contextual Recall Metric","description":"The Contextual Recall Metric evaluates the effectiveness of your Retrieval-Augmented Generation (RAG) pipeline\'s retriever by assessing how well the retrieved context (retrievalcontext) aligns with the expected output (expectedoutput). This metric ensures that the retriever captures and provides all relevant information necessary for generating accurate responses. Additionally, it offers explanations for its scores, making it a self-explaining LLM-Eval tool.","source":"@site/docs/ContextualRecallMetric.md","sourceDirName":".","slug":"/ContextualRecallMetric","permalink":"/DeepEvalSharpSite/docs/ContextualRecallMetric","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ContextualRecallMetric.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Contextual Precision Metric","permalink":"/DeepEvalSharpSite/docs/ContextualPrecisionMetric"},"next":{"title":"DAG (Deep Acyclic Graph) Metric","permalink":"/DeepEvalSharpSite/docs/DAGMetric"}}');var s=r(4848),l=r(8453);const i={},a="Contextual Recall Metric",o={},c=[{value:"When you should use Contextual Recall Metric",id:"when-you-should-use-contextual-recall-metric",level:4},{value:"When you SHOULDN&#39;T use Contextual Recall Metric",id:"when-you-shouldnt-use-contextual-recall-metric",level:4},{value:"How to use",id:"how-to-use",level:2},{value:"Optional Parameters",id:"optional-parameters",level:3},{value:"Samples",id:"samples",level:2}];function d(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"contextual-recall-metric",children:"Contextual Recall Metric"})}),"\n",(0,s.jsxs)(t.p,{children:["The Contextual Recall Metric evaluates the effectiveness of your Retrieval-Augmented Generation (RAG) pipeline's retriever by assessing how well the retrieved context (",(0,s.jsx)(t.code,{children:"retrieval_context"}),") aligns with the expected output (",(0,s.jsx)(t.code,{children:"expected_output"}),"). This metric ensures that the retriever captures and provides all relevant information necessary for generating accurate responses. Additionally, it offers explanations for its scores, making it a self-explaining LLM-Eval tool."]}),"\n",(0,s.jsx)(t.h4,{id:"when-you-should-use-contextual-recall-metric",children:"When you should use Contextual Recall Metric"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Evaluating Retriever Coverage"})," \u2013 Use this metric to assess whether your retriever captures all necessary information from the knowledge base to generate the expected output."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Optimizing Embedding Models"})," \u2013 Determine if your embedding model accurately represents and retrieves relevant information based on the input context."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Improving Retrieval Strategies"})," \u2013 Identify gaps in the retrieval process to ensure comprehensive information is provided to the generator."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"when-you-shouldnt-use-contextual-recall-metric",children:"When you SHOULDN'T use Contextual Recall Metric"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Assessing Response Quality"})," \u2013 If your goal is to evaluate the quality, fluency, or coherence of the generated responses, other metrics like Answer Relevancy or Faithfulness may be more appropriate."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Evaluating Ranking Performance"})," \u2013 When focusing on the order of retrieved information, the Contextual Precision Metric would be more suitable."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Resource-Constrained Environments"})," \u2013 Running LLM-based evaluations can be computationally intensive and may not be ideal for large-scale or real-time applications with limited resources."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"how-to-use",children:"How to use"}),"\n",(0,s.jsxs)(t.p,{children:["The Contextual Recall Metric requires ",(0,s.jsx)(t.code,{children:"input"}),", ",(0,s.jsx)(t.code,{children:"actual_output"}),", ",(0,s.jsx)(t.code,{children:"expected_output"}),", and ",(0,s.jsx)(t.code,{children:"retrieval_context"})," to function effectively. You can instantiate a Contextual Recall Metric with optional parameters to customize its behavior."]}),"\n",(0,s.jsx)(t.p,{children:"Instantiate a Contextual Recall Metric by using one of these static constructors:"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Constructor"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"ContextualRecall.Metric()"})}),(0,s.jsx)(t.td,{children:"Initializes a new instance"})]})})]}),"\n",(0,s.jsx)(t.p,{children:"Here's an example of how to use Contextual Recall:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-csharp",children:"var metric = ContextualRecall.Metric();\r\nvar result = metric.Evaluate(modelOutput);\n"})}),"\n",(0,s.jsx)(t.h3,{id:"optional-parameters",children:"Optional Parameters"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Parameter"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"threshold"})}),(0,s.jsx)(t.td,{children:"A float representing the minimum passing threshold, defaulting to 0.5."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"strict_mode"})}),(0,s.jsxs)(t.td,{children:["Enforces a binary metric score\u20141 for perfect recall, 0 otherwise\u2014and sets the threshold to 1. Default is ",(0,s.jsx)(t.code,{children:"False"}),"."]})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"samples",children:"Samples"}),"\n",(0,s.jsx)(t.p,{children:"We've given you a sample to work with that evaluates bla bla bla. Here's how you can run these samples:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-csharp",children:"var metric = ContextualRecall.Metric();\r\nvar result = metric.Evaluate(modelOutput);\n"})})]})}function h(e={}){const{wrapper:t}={...(0,l.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,t,r)=>{r.d(t,{R:()=>i,x:()=>a});var n=r(6540);const s={},l=n.createContext(s);function i(e){const t=n.useContext(l);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),n.createElement(l.Provider,{value:t},e.children)}}}]);