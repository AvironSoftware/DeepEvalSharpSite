"use strict";(self.webpackChunkdocs_src=self.webpackChunkdocs_src||[]).push([[3],{2585:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>c,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"metrics/HallucinationMetric","title":"Hallucination Metric","description":"The Hallucination Metric evaluates whether an LLM-generated actual_output contains fabricated or unsupported information by comparing it against the provided context, using an LLM-as-a-judge, reference-based approach. It flags hallucinated content and provides a reason for its score, making it a self-explaining LLM-Eval tool.","source":"@site/docs/metrics/HallucinationMetric.md","sourceDirName":"metrics","slug":"/metrics/HallucinationMetric","permalink":"/DeepEvalSharpSite/docs/metrics/HallucinationMetric","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/metrics/HallucinationMetric.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"GEval Metric","permalink":"/DeepEvalSharpSite/docs/metrics/GEvalMetric"},"next":{"title":"Prompt Alignment Metric","permalink":"/DeepEvalSharpSite/docs/metrics/PromptAlignmentMetric"}}');var r=n(4848),s=n(8453);const c={},a="Hallucination Metric",o={},l=[{value:"When you should use Hallucination Metric",id:"when-you-should-use-hallucination-metric",level:4},{value:"When you SHOULDN&#39;T use Hallucination Metric",id:"when-you-shouldnt-use-hallucination-metric",level:4},{value:"How to use",id:"how-to-use",level:2},{value:"Optional Parameters",id:"optional-parameters",level:3}];function d(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"hallucination-metric",children:"Hallucination Metric"})}),"\n",(0,r.jsxs)(t.p,{children:["The Hallucination Metric evaluates whether an LLM-generated ",(0,r.jsx)(t.code,{children:"actual_output"})," contains fabricated or unsupported information by comparing it against the provided ",(0,r.jsx)(t.code,{children:"context"}),", using an LLM-as-a-judge, reference-based approach. It flags hallucinated content and provides a reason for its score, making it a self-explaining LLM-Eval tool."]}),"\n",(0,r.jsx)(t.h4,{id:"when-you-should-use-hallucination-metric",children:"When you should use Hallucination Metric"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Detecting Fabrications"})," \u2013 Surface instances where the model asserts facts not supported by the provided context."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Validating Factual Outputs"})," \u2013 Check that LLM outputs align precisely with known source documents or context segments."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Benchmarking Model Precision"})," \u2013 Compare different LLMs or fine-tuned versions on their propensity to hallucinate."]}),"\n"]}),"\n",(0,r.jsx)(t.h4,{id:"when-you-shouldnt-use-hallucination-metric",children:"When you SHOULDN'T use Hallucination Metric"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Assessing Relevance or Completeness"})," \u2013 If you need to measure coverage or relevance rather than factual correctness, use Answer Relevancy or Contextual Relevancy."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Evaluating Creative or Fictional Outputs"})," \u2013 For poetry, stories, or other creative tasks where \u201challucination\u201d is expected, this metric is too strict."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Contexts Unavailable or Broad-Sweep Checks"})," \u2013 This metric requires explicit context segments; it\u2019s unsuitable when you lack a defined source of truth."]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"how-to-use",children:"How to use"}),"\n",(0,r.jsxs)(t.p,{children:["The Hallucination Metric requires three arguments to create an ",(0,r.jsx)(t.code,{children:"LLMTestCase"}),":"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"input"}),": the user prompt or query"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"actual_output"}),": the LLM\u2019s response"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"context"}),": a list of reference strings representing the source of truth"]}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Instantiate a Hallucination Metric by using the static constructor:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Constructor"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsx)(t.tbody,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"HallucinationMetric.Metric()"})}),(0,r.jsx)(t.td,{children:"Initializes a new instance of the metric"})]})})]}),"\n",(0,r.jsx)(t.p,{children:"Here\u2019s an example of how to use Hallucination Metric in C#:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:"var metric = HallucinationMetric.Metric();\r\nvar result = metric.Evaluate(modelOutput);\n"})}),"\n",(0,r.jsx)(t.h3,{id:"optional-parameters",children:"Optional Parameters"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Parameter"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"threshold"})}),(0,r.jsx)(t.td,{children:"A float representing the minimum passing score, defaulting to 0.5."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"include_reason"})}),(0,r.jsxs)(t.td,{children:["A boolean that, when set to ",(0,r.jsx)(t.code,{children:"True"}),", provides a reason for the metric score. Default is ",(0,r.jsx)(t.code,{children:"True"}),"."]})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"strict_mode"})}),(0,r.jsxs)(t.td,{children:["Enforces a binary metric score\u20141 for perfect relevance, 0 otherwise\u2014setting the threshold to 1. Default is ",(0,r.jsx)(t.code,{children:"False"}),"."]})]})]})]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>c,x:()=>a});var i=n(6540);const r={},s=i.createContext(r);function c(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:c(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);