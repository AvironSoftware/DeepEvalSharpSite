"use strict";(self.webpackChunkdocs_src=self.webpackChunkdocs_src||[]).push([[820],{8325:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>a,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"FaithfulnessMetric","title":"Faithfulness Metric","description":"The Faithfulness Metric assesses the quality of your Retrieval-Augmented Generation (RAG) pipeline\'s generator by evaluating whether the actualoutput factually aligns with the contents of your retrievalcontext. This metric focuses on identifying contradictions between the generated output and the provided context, ensuring that the information presented is accurate and trustworthy. Additionally, it offers explanations for its scores, making it a self-explaining LLM-Eval tool.","source":"@site/docs/FaithfulnessMetric.md","sourceDirName":".","slug":"/FaithfulnessMetric","permalink":"/DeepEvalSharpSite/docs/FaithfulnessMetric","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/FaithfulnessMetric.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"DAG (Deep Acyclic Graph) Metric","permalink":"/DeepEvalSharpSite/docs/DAGMetric"},"next":{"title":"GEval Metric","permalink":"/DeepEvalSharpSite/docs/GEvalMetric"}}');var i=s(4848),r=s(8453);const a={},l="Faithfulness Metric",o={},c=[{value:"When you should use Faithfulness Metric",id:"when-you-should-use-faithfulness-metric",level:4},{value:"When you SHOULDN&#39;T use Faithfulness Metric",id:"when-you-shouldnt-use-faithfulness-metric",level:4},{value:"How to use",id:"how-to-use",level:2},{value:"Optional Parameters",id:"optional-parameters",level:3},{value:"Samples",id:"samples",level:2}];function h(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"faithfulness-metric",children:"Faithfulness Metric"})}),"\n",(0,i.jsxs)(t.p,{children:["The Faithfulness Metric assesses the quality of your Retrieval-Augmented Generation (RAG) pipeline's generator by evaluating whether the ",(0,i.jsx)(t.code,{children:"actual_output"})," factually aligns with the contents of your ",(0,i.jsx)(t.code,{children:"retrieval_context"}),". This metric focuses on identifying contradictions between the generated output and the provided context, ensuring that the information presented is accurate and trustworthy. Additionally, it offers explanations for its scores, making it a self-explaining LLM-Eval tool."]}),"\n",(0,i.jsx)(t.h4,{id:"when-you-should-use-faithfulness-metric",children:"When you should use Faithfulness Metric"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Ensuring Output Accuracy"})," \u2013 Use this metric to verify that the generated responses are factually consistent with the retrieved context, minimizing misinformation."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Evaluating RAG Pipeline Integrity"})," \u2013 Assess the reliability of your RAG pipeline by ensuring that the generator produces outputs faithful to the retrieved information."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Identifying Contradictions"})," \u2013 Detect and address any discrepancies between the generated content and the source material to maintain credibility."]}),"\n"]}),"\n",(0,i.jsx)(t.h4,{id:"when-you-shouldnt-use-faithfulness-metric",children:"When you SHOULDN'T use Faithfulness Metric"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Assessing Language Quality"})," \u2013 If your goal is to evaluate the fluency, coherence, or stylistic aspects of the generated text, other metrics like Answer Relevancy or Summarization may be more appropriate."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Evaluating Retrieval Performance"})," \u2013 When focusing on the effectiveness of the retriever in fetching relevant documents, metrics like Contextual Precision or Contextual Recall would be more suitable."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Resource-Constrained Environments"})," \u2013 Running LLM-based evaluations can be computationally intensive and may not be ideal for large-scale or real-time applications with limited resources."]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"how-to-use",children:"How to use"}),"\n",(0,i.jsxs)(t.p,{children:["The Faithfulness Metric requires ",(0,i.jsx)(t.code,{children:"input"}),", ",(0,i.jsx)(t.code,{children:"actual_output"}),", and ",(0,i.jsx)(t.code,{children:"retrieval_context"})," to function effectively. You can instantiate a Faithfulness Metric with optional parameters to customize its behavior."]}),"\n",(0,i.jsx)(t.p,{children:"Instantiate a Faithfulness Metric by using one of these static constructors:"}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Constructor"}),(0,i.jsx)(t.th,{children:"Description"})]})}),(0,i.jsx)(t.tbody,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"Faithfulness.Metric()"})}),(0,i.jsx)(t.td,{children:"Initializes a new instance"})]})})]}),"\n",(0,i.jsx)(t.p,{children:"Here's an example of how to use Faithfulness:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-csharp",children:"var metric = Faithfulness.Metric();\r\nvar result = metric.Evaluate(modelOutput);\n"})}),"\n",(0,i.jsx)(t.h3,{id:"optional-parameters",children:"Optional Parameters"}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Parameter"}),(0,i.jsx)(t.th,{children:"Description"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"threshold"})}),(0,i.jsx)(t.td,{children:"A float representing the minimum passing threshold, defaulting to 0.5."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"include_reason"})}),(0,i.jsxs)(t.td,{children:["A boolean that, when set to ",(0,i.jsx)(t.code,{children:"True"}),", provides a reason for its evaluation score. Default is ",(0,i.jsx)(t.code,{children:"True"}),"."]})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.code,{children:"strict_mode"})}),(0,i.jsxs)(t.td,{children:["Enforces a binary metric score\u20141 for perfect precision, 0 otherwise\u2014setting the threshold to 1. Default is ",(0,i.jsx)(t.code,{children:"False"}),"."]})]})]})]}),"\n",(0,i.jsx)(t.h2,{id:"samples",children:"Samples"}),"\n",(0,i.jsx)(t.p,{children:"We've given you a sample to work with that evaluates bla bla bla. Here's how you can run these samples:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-csharp",children:"var metric = Faithfulness.Metric();\r\nvar result = metric.Evaluate(modelOutput);\n"})})]})}function d(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453:(e,t,s)=>{s.d(t,{R:()=>a,x:()=>l});var n=s(6540);const i={},r=n.createContext(i);function a(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);