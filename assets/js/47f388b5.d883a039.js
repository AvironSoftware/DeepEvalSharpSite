"use strict";(self.webpackChunkdocs_src=self.webpackChunkdocs_src||[]).push([[458],{136:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Answer Relevancy Metric","href":"/DeepEvalSharpSite/docs/AnswerRelevancyMetric","docId":"AnswerRelevancyMetric","unlisted":false},{"type":"link","label":"Contextual Precision Metric","href":"/DeepEvalSharpSite/docs/ContextualPrecisionMetric","docId":"ContextualPrecisionMetric","unlisted":false},{"type":"link","label":"Contextual Recall Metric","href":"/DeepEvalSharpSite/docs/ContextualRecallMetric","docId":"ContextualRecallMetric","unlisted":false},{"type":"link","label":"DAG (Deep Acyclic Graph) Metric","href":"/DeepEvalSharpSite/docs/DAGMetric","docId":"DAGMetric","unlisted":false},{"type":"link","label":"Faithfulness Metric","href":"/DeepEvalSharpSite/docs/FaithfulnessMetric","docId":"FaithfulnessMetric","unlisted":false},{"type":"link","label":"GEval Metric","href":"/DeepEvalSharpSite/docs/GEvalMetric","docId":"GEvalMetric","unlisted":false}]},"docs":{"AnswerRelevancyMetric":{"id":"AnswerRelevancyMetric","title":"Answer Relevancy Metric","description":"The Answer Relevancy Metric evaluates how relevant an LLM-generated actual_output is in relation to the given input. This metric is particularly useful for assessing Retrieval-Augmented Generation (RAG) pipelines and ensuring that responses remain on-topic and directly address the input query. The Answer Relevancy Metric provides a reason for its evaluation score, making it a self-explaining LLM-Eval tool.","sidebar":"tutorialSidebar"},"ContextualPrecisionMetric":{"id":"ContextualPrecisionMetric","title":"Contextual Precision Metric","description":"The Contextual Precision Metric evaluates how well a Retrieval-Augmented Generation (RAG) pipeline\'s retriever ranks relevant context higher than irrelevant context for a given input. This metric helps ensure that an LLM receives the most useful information, improving the accuracy and quality of generated responses. The Contextual Precision Metric provides an explanation for its evaluation score, making it a self-explaining LLM-Eval tool.","sidebar":"tutorialSidebar"},"ContextualRecallMetric":{"id":"ContextualRecallMetric","title":"Contextual Recall Metric","description":"The Contextual Recall Metric evaluates the effectiveness of your Retrieval-Augmented Generation (RAG) pipeline\'s retriever by assessing how well the retrieved context (retrievalcontext) aligns with the expected output (expectedoutput). This metric ensures that the retriever captures and provides all relevant information necessary for generating accurate responses. Additionally, it offers explanations for its scores, making it a self-explaining LLM-Eval tool.","sidebar":"tutorialSidebar"},"DAGMetric":{"id":"DAGMetric","title":"DAG (Deep Acyclic Graph) Metric","description":"The Deep Acyclic Graph (DAG) Metric in NEval allows you to construct deterministic decision trees for evaluating LLM outputs using an LLM-as-a-judge approach. This metric provides fine-grained control over the evaluation process by defining specific decision nodes and criteria, enabling precise assessments tailored to your application\'s requirements.","sidebar":"tutorialSidebar"},"FaithfulnessMetric":{"id":"FaithfulnessMetric","title":"Faithfulness Metric","description":"The Faithfulness Metric assesses the quality of your Retrieval-Augmented Generation (RAG) pipeline\'s generator by evaluating whether the actualoutput factually aligns with the contents of your retrievalcontext. This metric focuses on identifying contradictions between the generated output and the provided context, ensuring that the information presented is accurate and trustworthy. Additionally, it offers explanations for its scores, making it a self-explaining LLM-Eval tool.","sidebar":"tutorialSidebar"},"GEvalMetric":{"id":"GEvalMetric","title":"GEval Metric","description":"G-Eval is a framework within NEval that leverages large language models (LLMs) with chain-of-thought (CoT) prompting to assess LLM outputs based on customizable criteria. This versatile metric allows for human-like evaluations across various use cases by defining specific evaluation criteria or steps. Users can create custom metrics by specifying parameters such as \'input\' and \'actualoutput\', and optionally \'expectedoutput\' and \'context\', tailoring the evaluation to their specific needs. G-Eval also offers flexibility in configuration, including options for setting evaluation steps, thresholds, and selecting different LLM models.","sidebar":"tutorialSidebar"}}}}')}}]);