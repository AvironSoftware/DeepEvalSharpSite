"use strict";(self.webpackChunkdocs_src=self.webpackChunkdocs_src||[]).push([[958],{968:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>o,default:()=>d,frontMatter:()=>c,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"metrics/CustomMetric","title":"Custom Metric","description":"The Custom Metric feature allows you to define your own evaluation logic, either by composing existing EvalSharp metrics or by creating new rules tailored to your application. These user-defined metrics enable bespoke model validation for use cases not covered by out-of-the-box tools.","source":"@site/docs/metrics/CustomMetric.md","sourceDirName":"metrics","slug":"/metrics/CustomMetric","permalink":"/EvalSharpSite/docs/metrics/CustomMetric","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Contextual Recall Metric","permalink":"/EvalSharpSite/docs/metrics/ContextualRecallMetric"},"next":{"title":"Faithfulness Metric","permalink":"/EvalSharpSite/docs/metrics/FaithfulnessMetric"}}');var s=n(4848),i=n(8453);const c={},o="Custom Metric",a={},l=[{value:"When you should use Custom Metrics",id:"when-you-should-use-custom-metrics",level:4},{value:"When you SHOULDN&#39;T use Custom Metrics",id:"when-you-shouldnt-use-custom-metrics",level:4},{value:"How to use",id:"how-to-use",level:2},{value:"Example 1: Composite Custom Metric (Faithfulness + Answer Relevancy)",id:"example-1-composite-custom-metric-faithfulness--answer-relevancy",level:3},{value:"Example 2: Non-LLM as a Judge Match Metric",id:"example-2-non-llm-as-a-judge-match-metric",level:3},{value:"Configuration Options",id:"configuration-options",level:2},{value:"Notes",id:"notes",level:2}];function u(e){const t={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"custom-metric",children:"Custom Metric"})}),"\n",(0,s.jsx)(t.p,{children:"The Custom Metric feature allows you to define your own evaluation logic, either by composing existing EvalSharp metrics or by creating new rules tailored to your application. These user-defined metrics enable bespoke model validation for use cases not covered by out-of-the-box tools."}),"\n",(0,s.jsx)(t.h4,{id:"when-you-should-use-custom-metrics",children:"When you should use Custom Metrics"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Custom Evaluation Logic"})," \u2013 If your use case involves logic combining multiple metrics (e.g., both relevancy and factuality), define a custom score."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Don't want LLM as a judge"})," \u2013 Useful when don't want to use ",(0,s.jsx)(t.em,{children:"LLM as a judge"})," for your evaluations."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Compliance and Safety Checks"})," \u2013 Define domain-specific validation criteria to catch policy violations or logic inconsistencies."]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"when-you-shouldnt-use-custom-metrics",children:"When you SHOULDN'T use Custom Metrics"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Generic Evaluation Needs"})," \u2013 If existing metrics like ",(0,s.jsx)(t.code,{children:"BiasMetric"}),", ",(0,s.jsx)(t.code,{children:"AnswerRelevancyMetric"}),", or ",(0,s.jsx)(t.code,{children:"FaithfulnessMetric"})," suffice, use those directly."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Out-of-the-box Comparisons"})," \u2013 Use predefined metrics for rapid benchmarking across models and datasets."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"how-to-use",children:"How to use"}),"\n",(0,s.jsxs)(t.p,{children:["Custom metrics follow the standard metric interface and derive from the base ",(0,s.jsx)(t.code,{children:"EvalSharp.Scoring.Metric<TConfiguration>"})," class. You can implement your scoring logic using existing EvalSharp metrics or your own custom routines."]}),"\n",(0,s.jsx)(t.p,{children:"Implementing MetricConfiguration is optional, but if you would like visibility to additional parameters, this is suggested."}),"\n",(0,s.jsx)(t.h3,{id:"example-1-composite-custom-metric-faithfulness--answer-relevancy",children:"Example 1: Composite Custom Metric (Faithfulness + Answer Relevancy)"}),"\n",(0,s.jsxs)(t.p,{children:["This example defines a custom metric that returns the ",(0,s.jsx)(t.strong,{children:"minimum score"})," between Faithfulness and Answer Relevancy. It also returns combined reasoning for interpretability."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-csharp",children:'public class FaithfulRelevancyMetric : Metric<FaithfulRelevancyConfiguration>\r\n{\r\n    public FaithfulRelevancyMetric(FaithfulRelevancyConfiguration configuration) : base(configuration) { }\r\n\r\n    public override async Task<MetricScore> ScoreAsync(EvaluatorTestData testData)\r\n    {\r\n        var relevancy = new AnswerRelevancyMetric(_chatClient, new AnswerRelevancyMetricConfiguration());\r\n        var faithfulness = new FaithfulnessMetric(_chatClient, new FaithfulnessMetricConfiguration());\r\n\r\n        var relevancyScore = await relevancy.ScoreAsync(testData);\r\n        var faithfulnessScore = await faithfulness.ScoreAsync(testData);\r\n\r\n        return SetScoreReasonSuccess(testData, relevancyScore, faithfulnessScore);\r\n    }\r\n\r\n    public MetricScore SetScoreReasonSuccess(EvaluatorTestData testData, MetricScore relevancyMetric, MetricScore faithfulnessMetric)\r\n    {\r\n\r\n        var relevancyScore = relevancyMetric.Score;\r\n        var relevancyReason = relevancyMetric.Reasoning;\r\n        var faithfulnessScore = faithfulnessMetric.Score;\r\n        var faithfulnessReason = faithfulnessMetric.Reasoning;\r\n\r\n        // Custom logic to set score\r\n        var compositeScore = Math.Min(relevancyScore, faithfulnessScore);\r\n\r\n        var score = Configuration.StrictMode && compositeScore < Configuration.Threshold ? 0 : compositeScore;\r\n        var reason = Configuration.IncludeReason ? relevancyReason + "\\n" + faithfulnessReason : null;\r\n        var success = score >= Configuration.Threshold;\r\n\r\n        return new MetricScore(context)\r\n        {\r\n            Score = score,\r\n            Reasoning = reason,\r\n            Result = success ? MetricScoreResult.Pass : MetricScoreResult.Fail\r\n        };\r\n\r\n    }\r\n}\n'})}),"\n",(0,s.jsx)(t.h3,{id:"example-2-non-llm-as-a-judge-match-metric",children:"Example 2: Non-LLM as a Judge Match Metric"}),"\n",(0,s.jsxs)(t.p,{children:["This metric uses ",(0,s.jsx)(t.code,{children:"MatchMetric.Exact()"})," to check for word-for-word equality between the ",(0,s.jsx)(t.code,{children:"ActualOutput"})," and ",(0,s.jsx)(t.code,{children:"ExpectedOutput"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-csharp",children:"public class ExactMatchMetric : Metric<MetricConfiguration>\r\n{\r\n    public ExactMatchMetric(MetricConfiguration configuration) : base(configuration) { }\r\n\r\n    public override async Task<MetricScore> ScoreAsync(EvaluatorTestData testData)\r\n    {\r\n        var match = MatchMetric.Exact();\r\n        return await match.ScoreAsync(context);\r\n    }\r\n}\n"})}),"\n",(0,s.jsx)(t.h2,{id:"configuration-options",children:"Configuration Options"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Parameter"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"Threshold"})}),(0,s.jsx)(t.td,{children:"The minimum score required to pass the test (e.g., 0.6)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"StrictMode"})}),(0,s.jsxs)(t.td,{children:["If ",(0,s.jsx)(t.code,{children:"true"}),", enforces binary scoring\u20141 for perfect match, 0 otherwise. Applies to composite metrics."]})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"notes",children:"Notes"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["You can extend the ",(0,s.jsx)(t.code,{children:"MetricConfiguration"})," base class to pass additional flags or control scoring behavior."]}),"\n",(0,s.jsx)(t.li,{children:"You can mix and match any existing EvalSharp metrics within a custom metric."}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>c,x:()=>o});var r=n(6540);const s={},i=r.createContext(s);function c(e){const t=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:c(e.components),r.createElement(i.Provider,{value:t},e.children)}}}]);